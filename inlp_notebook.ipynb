{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1owGDSpSQ40",
        "outputId": "78dea3fc-a58f-4cf1-d54c-74903260dcb6"
      },
      "outputs": [],
      "source": [
        "# Uncomment if on colab\n",
        "\n",
        "# import os\n",
        "# os.chdir('/content')\n",
        "# !rm -rf LLM-Audting-Experiments\n",
        "# !git clone https://github.com/FabienRoger/LLM-Audting-Experiments.git\n",
        "# os.chdir('/content/LLM-Audting-Experiments')\n",
        "# !pwd\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnsXnUUKUJY6"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpQGF4SbloQW"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "from activation_utils import get_activations, get_all_activations, get_res_layers, run_and_modify, get_mlp_layers\n",
        "\n",
        "from activation_ds import ActivationsDataset\n",
        "from data_loading import PromptDataset\n",
        "from inlp import inlp\n",
        "from linear import get_linear_cut, get_multi_lin_cut\n",
        "from logit_lense import print_logit_lense\n",
        "from utils import make_projections, orthonormalize\n",
        "from tqdm import tqdm\n",
        "from metrics import get_avg_delta, get_perf_degradations\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCHE8nTpT_Rf",
        "outputId": "2f982cad-efb4-4d6b-942e-16138e73931f"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2-xl\").to(device)\n",
        "print(model.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9I48S8OAkX7"
      },
      "outputs": [],
      "source": [
        "ds_names = [\"men_v_women\", \"naive_black_v_white\", \"bash_v_powershell\"]\n",
        "prompt_dss = {n:PromptDataset(\"gpt2\", n) for n in ds_names}\n",
        "\n",
        "stud_layers_posibilities = {\n",
        "  \"mlp10-17\":get_mlp_layers(model, list(range(10,17))),\n",
        "  \"res10-17\":get_res_layers(model, list(range(10,17))),\n",
        "  \"mlp8-12\":get_mlp_layers(model, list(range(8,12))),\n",
        "  \"res8-12\":get_res_layers(model, list(range(8,12))),\n",
        "}\n",
        "dirs_fns = {\n",
        "    \"torch_inlp\":lambda act_ds: inlp(act_ds, 8, max_iters=200, use_torch=True, loading_bar=False),\n",
        "    \"svm_inlp\":lambda act_ds: inlp(act_ds, 8, max_iters=10_000, use_torch=False, loading_bar=False),\n",
        "    \"mlp\":lambda act_ds: get_multi_lin_cut(act_ds, 8, epochs=500, progress_bar=False)[0],\n",
        "}\n",
        "get_modif_fns = {\n",
        "    \"default\": lambda dirs, std_layer_name: {},\n",
        "    \"proj1\": lambda dirs, std_layer_name: dict(\n",
        "        [(layer, make_projections(dirs[:1], is_rest=std_layer_name.startswith(\"res\")))\n",
        "        for layer in stud_layers_posibilities[std_layer_name]]\n",
        "    ),\n",
        "    \"proj4\": lambda dirs, std_layer_name: dict(\n",
        "        [(layer, make_projections(dirs[:4], is_rest=std_layer_name.startswith(\"res\")))\n",
        "        for layer in stud_layers_posibilities[std_layer_name]]\n",
        "    ),\n",
        "    \"proj8\": lambda dirs, std_layer_name: dict(\n",
        "        [(layer, make_projections(dirs[:8], is_rest=std_layer_name.startswith(\"res\")))\n",
        "        for layer in stud_layers_posibilities[std_layer_name]]\n",
        "    ),\n",
        "}\n",
        "\n",
        "def to_run_fn(modif):\n",
        "  return lambda x, modif=modif: torch.softmax(run_and_modify(x, model, modif).logits[0].detach(), -1)\n",
        "\n",
        "\n",
        "to_eval_product = list(product(stud_layers_posibilities.keys(), dirs_fns.keys()))\n",
        "\n",
        "print(len(to_eval_product))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MgRlDbrhFXQ2",
        "outputId": "5052ba67-1359-43e2-c134-483b2d0f9b16"
      },
      "outputs": [],
      "source": [
        "for stud_layers_n, dirs_fn_n in to_eval_product:\n",
        "  for prompt_ds_n in prompt_dss.keys():\n",
        "    prompt_ds = prompt_dss[prompt_ds_n]\n",
        "    stud_layers = stud_layers_posibilities[stud_layers_n]\n",
        "    activations = get_all_activations(prompt_ds, model, stud_layers)\n",
        "    act_ds = ActivationsDataset.from_data(activations, stud_layers, device)\n",
        "    dirs = dirs_fns[dirs_fn_n](act_ds)\n",
        "    dirs = [d.to(device) for d in dirs]\n",
        "    for get_modif_fn_n, get_modif_fn in get_modif_fns.items():\n",
        "      print(stud_layers_n,dirs_fn_n, get_modif_fn_n, prompt_ds_n)\n",
        "      run_fn = to_run_fn(get_modif_fn(dirs, stud_layers_n))\n",
        "      run_fn_default = to_run_fn(get_modif_fns[\"default\"](dirs, stud_layers_n))\n",
        "      print(\n",
        "        get_avg_delta(prompt_ds, run_fn,loading_bar=False),\n",
        "        get_perf_degradations(prompt_ds, run_fn, run_fn_default,loading_bar=False),\n",
        "      )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Iterated Null.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('nine')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "7e401bd2233303e7e5c8d55bc5d8195e517ad4c847c84c926c1bcd5146436f9a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
